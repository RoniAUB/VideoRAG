[
  {
    "timestamp": "00:00",
    "text": "So, hello everyone. Welcome to the PC Seminar. Today we have this Professor Amir Mohad from American University of Beirut and he'll be talking on the GERT and Parametri's complex city of token sliding and token jumping. Thank you for joining us, Professor. Over to you now. Thank you, President. Thank you for having me. It's a real pleasure to be here. So, all right, let's jump right into it. So, since I did not really know the audience too well, I made the assumption that many of you maybe have not seen this area of combinatorial reconfiguration problems. So, I decided what I'm going to do is I'm going to give a gentle introduction to the area just to show you how many exciting problems and open problems are there. And then I will talk more about token jumping and token sliding, specifically what we know about them, what we knew about them before we started working on this project, what we managed to discover and the tons of questions that remain to be answered. Right, and it's a really, I mean, the questions are so nice to state, so easy to state, and they are accessible really to researchers at any level, which is one of the reasons why I enjoy working on these problems. So, so hopefully you'll get to enjoy them too. So, before I start, I should point out that this is joint work that started back in the combinatorial reconfiguration workshop almost two years ago. And it's joint work with Valentine Bart\u00e9, Nicolabuske, Le Mandalard, and Karl Lomer, who is my master's student. All right, so the outline of the talk, it's going to be in four sections. I will give a gentle introduction to combinatorial reconfiguration, because I know many of you might not have seen such problems. Then I will talk about token jumping and token sliding, what we know about them in terms of classical complexity or one dimensional complexity. Then I'll talk about the parameterized complexity of these two problems and what we know as of today, as we speak, and what are the problems that remain to be solved. And then the last part of the lecture is where I will put some of the technical stuff to show you to give you an idea about how we prove things when we deal with such problems and where are the difficulties and what kind of techniques have been developed. So I tried to keep the technical part as light as I could so that really we, I mean, I can focus on the big picture and the questions to be asked and answered. So if you have any questions along the way, please feel free to interrupt me either in the chat or by unmuting yourselves. So don't worry about leaving the questions till the end. You can interrupt me whenever you feel whenever I say something that doesn't make sense. Hopefully that won't happen too often. All right, so what is combinatorial configuration? So the best way I think to introduce is with a familiar example, which is one player games and the most common one that we use is the 15 puzzle game. So for those of you who don't know the 15 puzzle games, so you're given like a 4x4 grid and you have one empty square and basically you have all the remaining 15 squares are numbered from 1 to 15 and they come in some ordering and your job is to basically move the squares around so that all the numbers become ordered. So it's a by-ro so they have to be ordered this way. So if you notice in this figure, the only problem is that 14 and 15 are reversed but the only moves that you're allowed to do is to basically move a number into the empty square. And basically you have to do a sequence of moves so that you get all of the numbers in order. And for those of you who know this game, this example that I have on the slide is actually unsolved. There is no way you can flip the order in 15 of 14 and 15 in this puzzle. And I have a link here if you want to actually play the puzzle online which is pretty fun. So why do I do I start my talk by talking about 15 puzzle? It's because it's really I mean the way you solve the 15 puzzle tells you a lot about the area of combinatorial reconfiguration. So the standard way we would think about the 15 puzzle is by looking at the state space or what we call the reconfiguration graph of the 15 puzzle. So what does that graph consist of? Well, we have one vertex or one node in this graph for each possible configuration of the puzzle. So basically each possible configuration so it would be a possible permutation of the 15 numbers in addition to where you're going to put the empty square. Each one of those will be a vertex in the graph. And now we connect two vertices in that graph whenever one can be reached from the other by a single move. And what do we mean here by a single mover? It's basically just moving a number into the empty square. So if you look at the top node here in this graph, there are four possibilities that you can do in one move which we call a reconfiguration step which is you can move nine into the empty square. You can move three into the empty square, 12 or 15. And that gives us basically four neighbors of that vertex in the graph. Okay, and we call this whole graph the reconfiguration graph or the state space if you're more comfortable thinking about states, the states of the game. So now given this graph, the reconfiguration graph, there are tons of very interesting questions that you can ask about it. There are structural questions and there are algorithmic questions. And these are typically the types of questions that were interested in in this area of combinatorial reconfiguration. So a couple of examples about structural questions would be, well, the simplest one would be how big is this reconfiguration graph, right? How many vertices or how many edges? And that's usually not a very hard question to answer in terms of upper and lower ones. More interestingly, you can ask, is this reconfiguration graph connected, right? Or is, can I reach any state starting from any other state by a sequence of legal moves? And as I told you before, for the 15 puzzle, the reconfiguration graph is definitely not connected because there was no way to reverse 14 and 15 in the previous example that I showed you and you can easily prove that, by the way. So when it's not connected, another question would be how many components does I have? Is there some sort of a nice structure to the components of this graph? And then another question would be what is the diameter of this reconfiguration graph or of each one of its components? And that's usually a very important question to ask when you're dealing with one player games, because this could tell you like what would be the worst possible shortest path to reach a target configuration or to solve your game, to win your game, for example. And in the literature, this is sometimes known as God's number, which would be the diameter of the reconfiguration graph. And these are all very interesting, very interesting structural questions to ask about this reconfiguration graph. Now on the algorithmic side or the computational side, there's the obvious question of if I'm given a starting state and some ending state or target state, like in the case of the puzzle game, that I am given some starting state and we know what the goal state is. So here one decision problem would be to answer the question whether it's possible to get to the target state starting from some initial state that is also given to me. So you can decide to solve this problem either as a decision problem or as a search problem, which would give you the actual sequence of steps that will take you from a state to the target state. Other interesting computational problems, is it always possible to go from one configuration to any other? And this is basically also related to the structural question about connected components. And the last question that I will mention, which is also interesting, is how fast can you go from one configuration to another? Meaning, can you do it in at most case steps? There is a question I should wait or no. All right. So think about all of these questions that we paused using the simple 15 puzzle game. And now we're going to look at a lot of other possible problems where the same configuration graph can be extracted. And we can ask the same set of questions. So all of you here are familiar with the case sad problem. So you're given a Boolean formula and you want to know if you can satisfy this formula by assigning values to the variables. And we know that this is NP complete for K greater than or equal to 3. So now how can you transform this into a reconfiguration problem? Well, it's very simple. So now you're given a formula and you're given two satisfying assignments. So you can think of those satisfying assignments as bit vectors. And so now the question that you can ask is can I go from the first satisfying assignment as the next one by basically flipping one bit at a time under the condition that I remain a satisfying assignment at all times. And notice that without this condition, the problem is trivial. So you can basically just flip the bits however you like and reach S from T or T from S. But once you have this constraint of you should remain a satisfying assignment, the problem becomes way more interesting. And you can think of this problem again as walking in the solution space of the given formula of all the satisfying assignment of the formula. All right. So that's the sat reconfiguration problem. Let's look at another example. Graph coloring. We all know it. We all love it. You're given a graph and some integer K and you are asked whether you can properly k color the graph G. And we know again that this is NP complete for K greater than or equal to 3. How do you transform that into a reconfiguration problem? Well, now you're given a graph. You're given two colorings of the graph alpha and beta. And the question is can you recolor alpha to get the to beta? But you need to recolor 100x at a time and you need to remain a proper k coloring throughout. Same idea again leads us to this notion of the reconfiguration space where we are looking at the k colorings of the graph and how they are connected under this adjacent simulation that we define, which is a single vertex recoloring."
  },
  {
    "timestamp": "12:11",
    "text": "The final example that I will mention, which will be basically what we will focus on in the rest of the talk is token placement. I call it, but as you will all guess, this is the famous independent set problem. But we will look at it as a token placement problem because it will be more useful for the rest of the talk. So you're given a graph G and an integer k. And the question is can you place k tokens on your graph k black tokens so that no two of these tokens share an edge. And of course, we all know that this is an NP complete problem. So how can you transform this problem into a reconfiguration problem? Again, now I'm giving a graph two independent sets of the graph. Each of size k and the question is can I go from one independent set to the other under what rule. So here defining the rule for independent set, how can I go between consecutive independent sets becomes a little bit less obvious. And there are two main strategies that people have attempted. So the first rule is what we call token jumping. So you are basically allowed to take any token on your graph and jump it to any other vertex on the graph assuming that it doesn't have a token and that you maintain an independent set at all times. So for example, in this example that I have here, it would be perfectly okay to take this token here and jump it to this vertex here. Or I could also take this token here and jump it to this vertex here. So that no actually that would violate the independence. So you can jump to any other vertex as long as you maintain independence. And we call that the token jumping rule. The other rule is basically token sliding. So in this case, we only allow a token to slide along edges of the graph. So a token can only move to adjacent vertex assuming of course this does not violate independence. So now we have two different reconfiguration graphs we can think about. We can think about the reconfiguration graph under the token jumping adjacency. And we can think about the reconfiguration graph under the token sliding adjacency. And we're going to talk about these two different problems because they do actually behave quite differently and they produce quite interesting results like the difference between the two. We don't fully understand yet but we kind of know that token sliding can be harder than token jump. But there's still a lot of questions to be answered."
  },
  {
    "timestamp": "14:58",
    "text": "All right. So some of you might be asking why do we care about studying such problems? There's a lot of motivations out there. I mean, sometimes I would say you don't need motivation. They're interesting. There's a lot of open questions that we need to answer. But you can also think about reconfiguration problems as another way of modeling real world algorithmic problems because you usually never start from scratch. When you're trying to solve real world problems, you usually start from something and you're trying to prove it or make it better or change it to something more appropriate. Another very good application of studying these problems is that they give you a better understanding of solution spaces, which can be very important for other areas as well. And they have been used in statistical physics, quantum computing, and in complexity theory, combinatorics, and robotics, and hopefully many more applications to come. But what I would tell you is that there are so many very interesting problems that are so easy to start thinking about without having too much background, which is why I think this is a very nice area to start working on at any level in your research career."
  },
  {
    "timestamp": "16:19",
    "text": "All right, so I'll take a break here and take questions if there are any. And then we will dive into the token jumping and token sliding problems, what we know about them in terms of classical complexity and what was basically the starting point for the project that led us to this paper."
  },
  {
    "timestamp": "16:40",
    "text": "Any questions at this point?"
  },
  {
    "timestamp": "16:45",
    "text": "I'm, I'll apologize for the small context, which I'm interrupting here. So this is just to announce for the PC 301 workshop that will be happening in December end. And this will be slightly different from the previous two workshops. First major difference, this will be online. Second is some advanced topics, what we discuss. So anyone who intends to explore somewhat more complex topics in parametrize algorithms is invited to have a check. They can look at the website that has been shared on the chat. And if you wish, you can register simply by filling a form that is linked at the bottom of the webpage. So just to inform you all about it. And sorry for the interruption. Now, you can go. All right. All right. So let's start talking about token jumping, token sliding and a little bit about classical complexity. I know everybody here knows about P and NP. So I'm not going to talk about this. Some of you might not be familiar with the peace space class. So just a quick note, that's as much as you will need to know for this talk is that peace space is the set of all decision problems that can be solved using a polynomial amount of space. And the reason why I mentioned this class is because many many many many reconciliation problem actually are peace space complete. Okay. And so so what we know the standard inclusion is we know that P is contained in NP, which is contained in peace space. But a very useful thing about peace space is that savage prove that it's equal to NP space. So polynomial space and non deterministic polynomial space are the same class. Basically, and that's extremely useful when you start to think about reconfiguration problems, because if you think about a reconfiguration problem, where you're given some state and you want to reach the other one. So basically, you can solve that easily in non deterministic polynomial space. Which basically implies that they are in peace space. But actually, you can show a lot more than that. You can show that many, really many reconfiguration problems are actually peace space complete, which is not surprising. Right. The fact that many of these reconfiguration problems are peace space complete is not very surprising. Right. And then, them not being in NP is because they don't always have polynomial size certificates, which also makes sense. Because sometimes the number of steps that you need to take to go from one configuration to the other might very well be exponential in the graph size. But there are also some extremely surprising results. And these are some of the results, some of my favorite results in the area. So for example, you all know that coloring is NP complete, even for k equals three. However, it turns out that if you try to solve the recoloring problem for k equals three, it's actually polynomial time solvable. So if I give you two three colorings of a graph, and I ask you, is there a path between them that recolors one vertex at a time and never is and is always a valid three coloring, then this problem can be solved in polynomial time. And the recoloring problem only becomes peace space complete for k equals four and more. Right. So that's the first surprising result. Another very surprising result is that as your all FPT experts here, I know that you're all familiar with the fact that usually when we study problems on graphs of bounded bucket width, path width, tree width, they tend to become easier. It turns out that that's not really the case for reconfiguration problems, at least for token sliding and jumping, which is the two problems that are related to independent set. It turns out that those two problems remain peace space complete, even if you have a graph of constant tree width or path width or even bucket width. So a very, very, very simple graph structure still the problem remains hard."
  },
  {
    "timestamp": "21:11",
    "text": "All right. And finally, the last theorem that I also like a lot shows you basically that sliding and jumping behave differently. And it was shown that if you restrict yourself to bipartite graphs, where we know that max and independent set can be solved in polynomial time. If you restrict yourself to those graphs, it turns out that token jumping is NP complete, whereas token sliding is peace space complete, which is a strange difference between the behavior of those two problems."
  },
  {
    "timestamp": "21:54",
    "text": "All right. So in fact, we know a lot more about token sliding and token jumping. These problems have been at the heart of the area of combinatorial reconfiguration. They have been studied so much. And we know so much about them, at least in terms of standard or classical complexity. So some of the important results for our paper that we're going to focus on is this result. So that's going to be the starting point of the results that we will discuss next when we move to parametrize complexity. So the fact that token sliding and token jumping are peace space complete and then NP complete respectively on bipartite graphs was the starting point of our next paper. But there are some very interesting results here that are also worth mentioning. So for example, for even whole figure halves, we know how to solve token jumping in polynomial time. But the complexity of independent set even remains open on this class of graphs. And the complexity of token sliding also remains open. So we don't know how to check if given two independent sets, I can slide one to the other. Can you answer that question in polynomial time for even whole free graphs? For split graphs and cordal graphs, they also behave extremely differently, token sliding and token jumping. Right. So they are token sliding is peace space complete on split graphs and cordal graphs while token jumping is polynomial time. And that is some of the reasons why we feel that token sliding is harder usually than token jumping. But it's not always the case."
  },
  {
    "timestamp": "23:43",
    "text": "All right. So that's it for classical complexity. So now let's move on to parameterized complexity. And let's basically think about how you can parameterize those two problems, token jumping and token sliding. So there's the obvious parameter would be the number of tokens. Right. So one of the obvious parameters would be the number of tokens. So, so, and we're going to denote that by K. Another parameter would be the length of the sequence. Like how many steps does it take to go from one independent set to the other? You can also obviously parameterize by tree width or path width or any combination of the above. When we started working on this problem, our initial aim was to basically study the parameterized complexity of token sliding and token jumping on bipartite graphs using the parameter K number of tokens. Right. Because remember, we saw that token sliding is piece based complete on bipartite graphs and token jumping is NP. So you were interested to see if basically this is going to give us W1 hardness for token sliding and FPTNES for token jumping. All right. At least that that was the initial hope. That's why we started working on this project. We weren't able to answer the two questions. So we were able to answer one side of the question, which is we were able to show that on bipartite graphs, token sliding is in fact W1 hard. So token sliding parameterized by the number of tokens on bipartite graphs is W1 hard. We were not able to answer the question for token jumping. So that is still an open question. So having answered that question and failed on the next question, we started thinking about ways to basically simplify a little bit some of these questions. So the next thing we asked ourselves, so there are two directions where you can try and simplify. So the next thing we asked ourselves was, okay, so from bipartite graphs, how can I go to other classes of graphs and see where token jumping becomes hard or easy? And it turned out that if you basically exclude only C4 from your graph, right? And so we, because in bipartite graphs, you're excluding all odd cycles. Right? So, so we, and we started thinking about what kinds of cycles affect the behavior of those problems. So the first question was, what about C4 free graphs? And it turned out that both problems remained W1 hard on C4 free graphs. Now, if you exclude C3 and C4, it turns out that token jumping becomes FPD has an order K squared kernel, but for token sliding, we were not able to determine the complexity. Now, if you go to the other side of that, so what if we enforce both bipartite tightness as well as C4 freeness? So on, in that case, we were able to show that both problems became FPD."
  },
  {
    "timestamp": "27:13",
    "text": "Okay, and basically the bipartite bounded degree graphs was just a stepping stone to get to the bipartite C4 free graph result. So let me, let me repeat that maybe slightly more clearly. So after basically answering the first question, which was bipartite graphs, we were able to show that token sliding was W1 hard, but we were not able to determine the complexity of token jumping. So then we went to C4 free graphs, and we were able to show that both problems are actually W1 hard. Then if we added one more constraint, which was C3 C4 free graphs, we got FPDness for token jumping, but it remained open for token sliding. And on the other side of the spectrum, so if we keep bipartite and enforce the C4 freeness, we get FPD for both problems. And as a side note, this blue result is not part of our paper. This was known prior to our paper. So any questions about the results? No questions. All right, cool. So lots of open problems. The first and obvious one is, what is the pattern is token jumping FPD, parameterized by K on bipartite graphs. And that's really, I mean, that was the initial question that we set out to answer. And couldn't. So that remains open. And it's, so I will not be going over the hardness reduction for token sliding on bipartite graphs, because it's quite technical. I don't feel a talk is the right place to go over it. But if you go over the reduction, you will see that it's the two problems really behave differently. And there's that doesn't seem to be a chance to basically make the same type of reduction work for token jumping. So the second interesting open question is, how about token jumping parameterized by K on triangle free graphs? That's basically even more general than question one. Right. So, and the reason why I mentioned this question separately is because almost every reduction that I know of includes large clicks. So you need to use large clicks in your reductions. So how about if we don't allow trying those and large clicks, so can we can we can we then say something about the problem? So that's for token jumping. Now, when when you go to token sliding, so so the open problem is what happens for token sliding on graphs of girth at least five, so if they are C3 C4 free, or you can even make that a bit weaker and ask for any girth of at least P for some constant P. And for all of these questions, of course, polynomial kernels would be interesting as well, because in our case, we do get polynomial kernels for the FB."
  },
  {
    "timestamp": "30:47",
    "text": "And the polynomials are not great, but polynomial, regardless."
  },
  {
    "timestamp": "30:56",
    "text": "All right. So in the rest of the talk, I will try to cover some of the technical stuff. And as promised, I will try to keep it as light as possible so that I can give you some of a lot of the intuition and techniques that are used in this paper and that are generally used when dealing with the reconfiguration problems. So the first result that we will go over is this W hardness on C4 free graphs. Right. For both token sliding and token jumping, it's the same reduction and and you will get both results because we will be using maximum independent sets. So if you're trying to basically do token sliding from one maximum independent set to the other, or token jumping, these two rules become equivalent, jumping becomes equivalent to sliding. So when you're dealing with maximum independent sets, these two basically rules are the same. And that's what we're going to do. But what we're going to prove actually is a stronger theorem. What we're going to prove is the following theorem. If you take any p greater than or equal to four, then both problems are W hard on C4, C5 dot dot dot up to Cp free graphs, which implies of course C4 free graphs. But you can basically exclude any cycles from C4 up to Cp for constant P and the problems will remain W1 hard. So how do we prove this result? In fact, we use a known reduction from a problem known as grid tiling, which is a W1 hard problem. And grid tiling is reduced to the independent set problem on C4 up to Cp free graphs. And that reduction was used to show that independent set remains W1 hard if you exclude C4 up to Cp for any constant P. But what is interesting and useful in that reduction is the graph that is obtained from the reduction. So the graph that is obtained from the reduction has three properties that are going to be useful to us. The first property is that you can partition the graph into basically 8k squared into P plus 1 clicks. So you have a bunch of clicks each of size n and all of the edges basically are between the clicks. But that's it, that's the whole of the graph. It's a bunch of clicks and edges between them. Of course, the more important property as well here is that this graph is going to be C4 up to Cp free. It will not have any of those cycles as an induced sub graph. And it's an equivalent instance to the grid tiling instance. And that basically gives you a W1 hardness of independent set on this class of graphs. So notice in this case that an independent set of size 8k squared into P plus 1 will have to be a maximum independent set because that's how many clicks we get in the resulting graph. And that's basically the sizes that we will be working with, more or less up to some modifications. But this will allow us to basically conclude that both sliding and jumping are hard on this class of graphs. So how do we use this for showing hardness of token sliding and token jumping? And let's focus on token sliding for now because it's going to be the same anyway. So we have those clicks and some edges that go between the clicks. So the first attempt would be as follows. We will add a universal vertex to each one of the clicks and we will call this the starting set or the starting independent set. And then we add another universal vertex to each one of the clicks and call this the target independent set. And now basically we have our instance of token sliding. We want to slide everybody in S down to T. So notice that this is useful because we don't introduce any of the forbidden cycles. So we are still fine. And if we could guarantee that all of the tokens will be on the on the clicks simultaneously, then this will imply an independent set in the original graph, which concludes our proof. But unfortunately in this case, we definitely cannot conclude that because each rent token can slide independently here and then here and then the next one can follow, etc, etc, etc. So you need some way of forbidden, are forbidding the tokens to behave freely. We want to make sure that they will all be inside the clicks simultaneously and we will be done. And notice that we're going to have 8k squared and 2p plus 1 tokens, right? 1 for each click and 2 universal vertices for each click. So how do we fix this time of 1080 issue? Well, here's how we can do it. So instead of simply adding universal vertices, we're also going to add an edge between every two universal vertices of a click. And then we're going to add something that we call a switch. And in this case, it's a simple edge and the red token needs to go to the blue position. Right? So now we have one extra token inside our graph. But now notice what happens. If any red token wants to come to the blue position, then this red token needs to be moved to this position before. And if you move that token up to the blue position, then you can no longer have any of the red tokens on the universal vertices, which means that they will all have to be simultaneously inside the clicks. And now we get the behavior that we want. So now we can guarantee that if there is a sequence that takes the red tokens to the blue position, then somewhere along that sequence, the tokens are all going to be within the clicks. Unfortunately, what happened here is we might have introduced some of the forbidden cycles. We can no longer guarantee that this is C4 up to CP3. So what you can do in this case to solve this problem, and I'm not going to go into the details, but the intuition should be pretty clear, is that you can subdivide those edges, make them long enough so that you don't introduce any forbidden cycles, and add appropriate tokens inside of them to get the same behavior. Because notice that the number of such edges is bounded by a function of K, by a function of yes, K and P. This case. Right, so you can make these edges subdivide them as many times as needed, add as many tokens as needed to maintain all the properties that we need, and to maintain that we're going from one maximum independent set to the other, which will give you W1 hardness for both token sliding as well as token jumping. All right, questions? All right, so let's keep going. So now I'm going to talk about some positive result. So the result that I'm going to talk about is this one here. Right, so I'm going to show you that on C3, C4 free rafts, token jumping is actually FPD and has a quadratic kernel, but again, what we will show is a stronger result. So what we will show is the following theorem. What we will show is can be summarized as follows. So if you look at any graph or at any instance of the token jumping problem. So remember, an instance of token jumping has the input graph, the starting set, the target set, and K as the number of tokens. So let me try and draw something here. So if you look at your graph, you can kind of decompose it into something which is more or less as follows. So you have S, you have T, the intersection need not be empty. And then you have the neighborhood of S union T. And then you have the rest of the graph."
  },
  {
    "timestamp": "40:33",
    "text": "So we're going to call the rest of the graph H. And we're going to call the close neighborhood of S union T, or if you will, this yellow part here, we call that J. So we can think of our problem of our graph as being decomposed into those two areas, H and J. Okay, so the theorem states the following. If H is epsilon sparse, where epsilon sparse means that the number of edges is at most and squared minus epsilon positive epsilon. So if H is epsilon sparse and J is C3C for free, then the problem admits a kernel, which is that big, K squared plus K into 1 plus 1 over epsilon. So notice now that we only need that H is epsilon sparse. And we only require C3C for freeness inside J, which is S union T close neighborhood of S union T."
  },
  {
    "timestamp": "41:45",
    "text": "And this idea is actually is not a new idea. So this idea is, is, okay, I had the drawing here, I should have used it. So the idea comes from has been used before. And it's what we call the buffer technique for the token jumping problem. And the solution behind the buffer technique is very simple. So if I have S union T, but somewhere in the graph, which is not in the close neighborhood of S union T, I have a K sized independent set, then you are done. Right? If I have a K sized independent set in H, then you're done. You can basically take all the tokens on S, jump them into those independent yellow vertices in H, and then jump them back to T. So in some sense, when H has a large independent set, that's the easy case. Right? You're done. If you can find a large enough independent set in H, you're done. And that's what we call the buffer technique. Because it's been also used to show that the problem is FBT on planar graphs, for example. Or K3J free graphs. So graphs without large bi-clips. So it's a well-known technique. All right. So what do we show? So we're going to use the buffer technique, and we're going to combine it with something else. So we show that you have a yes instance whenever one of those two conditions is true. The first condition is that H is epsilon sparse and contains more than this many vertices. And this is relatively easy. When you contain this many vertices and you are epsilon sparse, then you will have a K size independent set. And that's basically the buffer technique. When H is epsilon sparse and has that many vertices or more, then H is guaranteed to have an independent set of sparse K and you're done. So now you are stuck with what happens inside J, or the closed neighborhood of S-Union T. And it turns out there, if you have C3C for freeness, the only thing you need on top of that to guarantee a yes instance is a vertex of degree at least 3K. So if you have C3C for freeness inside J and the vertex of degree 3K, then again you get a yes instance. So let me prove those two statements separately, because they will be basically what we need for the final theorem for the final theorem. So the first lemma as I told you, if H is epsilon sparse and has more than this many vertices, then it's a yes instance because you have a K size independent set in H. The idea of this proof is simple, it's a counting argument. And what you need to do basically first is to show that H must contain a vertex of degree less than an over K. And then basically you apply the standard greedy packing algorithm for constructing an independent set of size K. And the reason you show that the way you show that H has a vertex of degree less than an over K is, again, standard counting argument and the hand shaking lemma. So if the minimum degree in H was at least an over K, then the number of edges would be at least n squared over 2K, which will only happen in an epsilon sparse graph when n is less than or equal to K to the power 1 over S. And the rest of the proof is basically an induction on K. Okay, and so that shows you that when you do have an epsilon sparse graph with more than this many vertices, then we have a yes instance. All right, so how about the second part of the claim? So now what happens if we have a C3 C4 free J that has a vertex of degree 3K? Well, let's see what happens. So if we have a vertex of degree 3K and I'm going to circle it here in yellow. So how can the neighborhood of that vertex look? Well, we know that J is C3 free. So the blue edges cannot exist, which means that the neighborhood of the yellow vertex is an independent set inside J, not in the whole graph. Well, in fact, in the whole well known because we're only talking about J as a sub graph. Right? So the blue edges cannot exist because otherwise we will get a C3 inside J. All right, so now let's look at the other vertices in S union T. The other the second observation that you need is that any vertex other than the yellow vertex can have at most one neighbor in common with the yellow vertex. Because if you do have two neighbors in common, then you will get a C4."
  },
  {
    "timestamp": "47:15",
    "text": "So now what happens if we have three k vertices in the neighborhood of the yellow vertex? Well, at most two k of them can be connected to some vertex in S union T and you will get at least k of them, some k of them here that are only connected to the yellow vertex. And so now basically instead of using a buffer inside H, we have just found a buffer inside J and we can use the same strategy. We can jump all the tokens here starting of course by the yellow token and then jump them to where they need to go."
  },
  {
    "timestamp": "48:04",
    "text": "So now combining those two"
  },
  {
    "timestamp": "48:08",
    "text": "observations together if you will, we get the following theorem. So if H is alpha sparse and J is C3 C4 free, then the problem admits a kernel on this maneuver to C's. And it's basically a simple application of the previous two lemmas. If we have more than this maneuver to C's in H, it's a trivial yes instance. If J has a vertex of degree 3k or more it's trivial yes instance and now you combine all of this together, we know that S union T is of size at most 2k, we know that the neighborhood of S union T is of size at most 2k times 3k, which is roughly 6k squared. And now we know that the rest of the graph has at most that maneuver to C's. So basically use some of those numbers and you get this bound. All right. So how does this theorem imply that result that I promised you to start with?"
  },
  {
    "timestamp": "49:15",
    "text": "So that token jumping and token sliding admit kernel with order k squared vertices. I mean, it also holds for bipartite C4 free graphs, right? Obviously because they are C3 C4 free. So how do you get the kernel? Well, we know that J cannot contain more than 6k squared minus 2k vertices. And we know from another theorem from another paper that C3 free graphs with k squared over log k vertices must have an independent set of size at least k. And now we know that if H contains more than this many vertices, then we will get a yes instance as well. Right. So it becomes an immediate consequence of the previous theorem, but the previous theorem is even more general than this corollary. So this corollary does not really use the full power of this theorem. All right. That's it. I think I'm fine. If you have questions, I will take them now."
  },
  {
    "timestamp": "50:29",
    "text": "So it was 55 minutes, right? For the talk. I did not go under the talk. It's fine. We usually allow plus minus 10 minutes. That's all right."
  },
  {
    "timestamp": "50:42",
    "text": "So I have a question about token sliding. Yes. So how crucial, what happens if one does not restrict the independent sets during the configuration to be not of the same size? Is that very critical for the difficulty or the easiness of the problem? Well, you have to be careful how you define that because in token sliding, tokens cannot leave the graph. That's correct. But the independent set sequence, all the independent sets have to be the same size, right? Or if not some token disappeared at some point, and I'm not sure how it disappeared. Right. Because you start with something of size k, and you're going to something of size k, you cannot leave the graph unless you define it in some way. So you will remain of size k throughout. But you can become slightly larger in k. But where does the new token come from?"
  },
  {
    "timestamp": "51:49",
    "text": "So there is a third rule that I did not tell you about, which is called token addition and removal. So under that rule, we actually allow you to remove vertices and adversities as long as you remain an independent set of size at least k."
  },
  {
    "timestamp": "52:10",
    "text": "Does that answer your question? Yeah. Yeah. Yeah. Yeah. But in fact, it was shown that it was shown that so addition and removal is equivalent to token jumping. I see. I see. It doesn't, it never makes sense to add more tokens to your graph if you don't need them."
  },
  {
    "timestamp": "52:34",
    "text": "You're only making your life harder into it if he's speaking."
  },
  {
    "timestamp": "52:41",
    "text": "So the other question that I had is, I mean, I heard, I,"
  },
  {
    "timestamp": "52:46",
    "text": "so is it possible to view this whole problem on an exponential size graph? Where every vertex corresponds to an independent set in the original graph? And then you have edges between two vertices. If there is an edge between two vertices of the independent set. And now you're doing a reachability question. Is that a meaningful way to think about this? But that's exactly what we're doing. So the way you define your adjacency, I think. So you mean you define, you make two independent sets adjacent if one can be reached from the other via a single slide or a single joint. Exactly. Yeah. One edge here. There is one pair, you and B, which is adjacent. But that's, but that's exactly what we're doing. Okay. Okay. Yeah. Right? I mean, if you, because we're looking at algorithms here, we kind of forget the structural picture behind it. But this algorithm is finding a path in this graph that you're describing. Yeah. Yeah. That's right. And what we're saying is you can do it in FBT time or not, depending on the problem we're talking about."
  },
  {
    "timestamp": "54:05",
    "text": "Hi, Amir. Hi. Hi. Hi. How are you? Hi. How are you? Hi. Yeah, I'm good. So I had a question. So do problems remain equally hard if we bound the, if we have a restriction on the number of times, we can move the token to a particular vertex."
  },
  {
    "timestamp": "54:28",
    "text": "The number of times you can move a token to a particular vertex. I like it. The number of times the tokens can be moved to a vertex. Well, that's definitely going to change the complexity in, at least intuitively speaking, right? Because now you're saying maybe it will, if you're bounding that by a constant, then you might be saying that I'm not allowing exponentially large sequences anymore. But in terms of exactly how the complexity changes, I don't have answers. I think it's a very nice question to pose. Even in terms of a non-parameterized complexity, standard complexity, I think that that would be a very interesting question. Because it will definitely affect the behavior. I'm not sure exactly how yet. I don't know of any results that ask this particular question. Okay. So I had one more question in the W hardness result that you presented. Yeah. So do you know what is the length of the, the length of the changes, actually the number of changes or flips that you make in your independence? This is just, yes, yes, yes, we do. So here the number of changes is going to be where it's basically going to be the shortest possible sequence. So it's going to, it's, it's, it's basically going to be, so if you think about the simple construction, this one,"
  },
  {
    "timestamp": "56:04",
    "text": "it's basically literally going to be these guys are going to move here. So each is going to cost me one slide and then they're all going to, and now this guy is going to move here and now I will pay one slide for each one here. Now this is the simplified version of it. Once you go to the complete version of it, you have some extra slides within the path, but you can also count those. Okay. So, but does this mean that, so does this mean that at a particular vertex, we are placing the token at most once? In this case, yes. Okay. In this case, yes. Okay. So this problem should be hard even if we bound the number of times tokens can be moved to a vertex, right? Yes. Okay. Yes. So here in this case, yes. Absolutely. Okay. Thanks. So, Akansha, I have a remark about your question. So if a vertex, if a vertex cannot get a token to I's, then it somehow seems to be selecting disjoint independent sets."
  },
  {
    "timestamp": "57:20",
    "text": "A sequence of them and that may have some bearing on coloring. Just a top level."
  },
  {
    "timestamp": "57:30",
    "text": "So, actually for the list, the W hardness case that I'm going to present it, it is exactly the case, right? So we are not allowed to move the token like twice on the same vertex. Yeah. So I didn't get your point of being, so getting this disjoint independence, it's actually because if you say, if you think of it from my, the way I thought about it, right, that you are actually trying to find a path in a large graph where every vertex corresponds to an independent site and you move from one independent site to another. What? So, but we can only move from one independent site to the other if the, if the change is, is like in case of tokens sliding, it's one probably. Yeah."
  },
  {
    "timestamp": "58:22",
    "text": "So it looks to be that you are asking for a collection of independent sets which are vertex disjoint. If the token sequence of independence is which of vertex disjoint. Yeah. So if I may, I think, I think, a conscious question would be more relevant in a place where we don't have a monotone sequence, meaning a sequence. So we need a version of the problem or some cases of the problem where a vertex has to be visited multiple times to find solutions. And that is known to be the case for some versions or some statements of the problem. And in fact, the conscious also, this was the crucial difference between piece-based completeness and NP completeness of sliding versus jumping in bipartite graphs. So it was because we were able to show that no vertex will be visited more than once. Okay. And the other problem. So, so that's why it's definitely an interesting question to pose, but you have to be careful in what context you pose it. Great. I don't know if that kind of settles answers your question. Yes, yes, it does. All right. Thanks. You're welcome."
  },
  {
    "timestamp": "59:47",
    "text": "Any more questions?"
  },
  {
    "timestamp": "59:56",
    "text": "Thank you."
  },
  {
    "timestamp": "60:19",
    "text": "I guess no. I don't think that I'm going to go show. So I will just once again announce the parameterized and go to the 301 workshop which is going to happen in December in the link has been posted once again in the chat. Some advanced topics in parameterized complexity will be discussed. Those interested can have a look and register for it. And yeah, if there are some more questions please ask away. So anyone can register for the program. Yes, he's anyone can. Yeah, it's free and it's online and yeah, it's open to everyone. So I can share it with my students as well. Of course, of course, please do. Yeah, that will be good. And we assume some basic understanding of parameterized algorithms. But we have already shared a link on the page where students can go and go through some previous lectures in parameterized algorithms if they wish to just brace up or revise stuff. All right, so I guess, okay, I don't think there are any more questions. So I give this a good time to wrap up. So thank you once again, Professor Amitur, for agreeing to give the talk. It was really nice to have you and it was really good to have something different than what we usually hear in every parameterized complexity talk, at least most of them. So and yeah, these are really interesting problems to think of on. And thank you to the audience for being with us. And that's it for today's wrap up. See you all next week. Thank you. Bye. Thank you, bye bye."
  }
]